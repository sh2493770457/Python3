import os
# 定义空列表用于保存处理后的链接
urls_list = []

# 读取原始文件并处理 URL
with open(r'C:/Users/24937/Desktop/url.txt', 'r', encoding='utf-8') as f:
    urls = f.readlines()
    for url in urls:
        # 去掉每行的多余空白字符
        url = url.strip()
        # 检查 URL 是否缺少 http/https 前缀
        if not url.startswith('http://') and not url.startswith('https://'):
            url = 'http://' + url  # 添加 http:// 前缀
        urls_list.append(url)  # 将处理后的 URL 加入列表
        print(url)


# 将处理后的 URL 列表保存到新文件
# with open(r'E:\PycharmProjects\PY\测试\Shiro_exploit\xiaoyi\saucerframe\url.txt', 'w', encoding='utf-8') as f:
#     for url in urls_list:
#         f.write(url + '\n')

# 执行系统命令调用脚本
os.system(f'java -jar ScanShiro_v2.0.jar -f url.txt -k key.txt')